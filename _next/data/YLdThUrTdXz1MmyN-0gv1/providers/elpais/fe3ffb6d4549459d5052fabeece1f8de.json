{"pageProps":{"page":{"id":"fe3ffb6d4549459d5052fabeece1f8de","pt-br":{"title":"Facebook tolerou discursos de ódio em países em guerra em prol de seu crescimento","byline":"María Antonia Sánchez-Vallejo","content":["<figure><span><img alt=\"Frances Haugen na segunda-feira em Londres, durante depoimento a uma comissão do Parlamento britânico.\" decoding=\"auto\" height=\"276\" srcset=\"https://imagens.brasil.elpais.com/resizer/2KGiln5xrY4U8Yflslcc8_3wpyU=/414x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg 414w,https://imagens.brasil.elpais.com/resizer/BqHGUzBOcR1EMAJ7LeNAzxwxn7g=/828x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg 640w,https://imagens.brasil.elpais.com/resizer/HTPrw0YeAUk0_v7bMCECvFpsal4=/980x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg 1000w,https://imagens.brasil.elpais.com/resizer/tbMG8jR7KhrQP0RCS0wJmXpdzRs=/1960x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg 1960w\" width=\"414\" loading=\"lazy\" src=\"https://imagens.brasil.elpais.com/resizer/2KGiln5xrY4U8Yflslcc8_3wpyU=/414x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg\"/></span><figcaption><span>Frances Haugen na segunda-feira em Londres, durante depoimento a uma comissão do Parlamento britânico.</span><span>DPA vía Europa Press  (Europa Press)</span></figcaption></figure>","<p>O Facebook se tornou um aprendiz de feiticeiro <a href=\"https://brasil.elpais.com/sociedade/2021-10-05/facebook-da-start-up-que-fascinou-o-mundo-ao-imperio-que-todos-querem-derrubar.html\" target=\"_blank\">cujo sucesso fugiu de seu controle</a>. A revelação de documentos internos da rede social segundo os quais seus executivos permitiram, por ação ou omissão, a publicação de desinformação e conteúdo polêmico se voltou como um bumerangue contra a empresa. Essas informações provocaram a pior crise de reputação de sua história, que já incluía episódios obscuros sobre a privacidade dos dados, como o <a href=\"https://brasil.elpais.com/brasil/2018/05/02/internacional/1525285885_691249.html\" target=\"_blank\">caso da Cambridge Analytica</a>.</p>","<p>Assim como as empresas de tabaco em outra época, ou como a farmacêutica que fabricou o medicamento responsável pela grave crise de opioides nos EUA —todas negando a possibilidade de vício—, o Facebook enfrenta o grande momento da verdade: depois da idílica comunidade global que pretendeu criar, ele contribuiu para <a href=\"https://brasil.elpais.com/tecnologia/2021-09-15/facebook-admite-em-documentos-internos-que-o-instagram-e-toxico-para-muitas-adolescentes.html\" target=\"_blank\">prejudicar a convivência por ignorar conteúdo potencialmente violento</a>, como discursos de ódio em países onde essas mensagens podem ter graves consequências, pelo que indicam os documentos revelados.</p>","<p>A constatação da negligência não se aplica apenas aos EUA de Donald Trump —com o auge das <i>fake news</i> graças às redes sociais, <a href=\"https://brasil.elpais.com/internacional/2021-03-26/google-facebook-e-twitter-admitem-ao-congresso-que-desempenharam-um-papel-no-ataque-ao-capitolio.html\" target=\"_blank\">e consequências como o ataque ao Capitólio em 6 de janeiro</a>— ou à porcentagem ainda pequena de vacinação contra a covid-19 por culpa de <a href=\"https://brasil.elpais.com/brasil/2021-10-25/facebook-e-instagram-bloqueiam-live-semanal-de-bolsonaro-apos-presidente-vincular-aids-a-vacina-contra-covid-19.html\" target=\"_blank\">teorias não científicas que o Facebook ajudou a fomentar</a>. A falta de controle da empresa sobre seus conteúdos também causou estragos na Índia, ao potencializar a política de nova <i>hinduização</i> do país por parte do nacionalista Narendra Modi. E em Mianmar, atiçando a perseguição contra a comunidade rohingya. E também no Afeganistão, no Iêmen, na Etiópia.</p>","<p>Isso se depreende do último conjunto de documentos internos vazados para um consórcio de veículos de comunicação internacionais, os chamados <i>Facebook Papers</i>. Uma questão central é determinar se o próprio funcionamento da plataforma deu origem ao problema; ou seja, se as ferramentas que tornaram o Facebook aquilo que ele é hoje —<a href=\"https://brasil.elpais.com/brasil/2019/05/24/tecnologia/1558709847_170516.html\" target=\"_blank\">os botões de curtir e de compartilhar conteúdo</a>, tão intuitivos— multiplicaram exponencialmente o risco na ausência de uma moderação adequada das publicações.</p>","<p>As revelações, <a href=\"https://brasil.elpais.com/tecnologia/2021-10-05/a-garganta-profunda-do-facebook-exige-uma-legislacao-para-conter-a-rede-social.html\" target=\"_blank\">baseadas em entrevistas com ex-funcionários e relatórios internos</a>, mostram como a expansão global da empresa —presente em mais de 190 países e mais de 160 idiomas, com mais de 2,8 bilhões de usuários por mês— negligenciou o controle do conteúdo por causa, em muitos casos, de um número insuficiente de moderadores com conhecimento adequado dos idiomas e contextos locais para identificar publicações potencialmente perigosas —ou no mínimo duvidosas— em muitos países em desenvolvimento. Em 2019, além disso, a empresa reduziu seu orçamento para a contratação de moderadores, em prol das máquinas.</p>","<p>Os vazamentos também revelam que os sistemas de inteligência artificial (IA) usados pelo Facebook para evitar esse tipo de conteúdo são, muitas vezes, ineficazes, assim como as ferramentas para o possível aviso de um usuário. A descrição mostra um Facebook hipoteticamente blindado contra as denúncias, ao que se soma, além disso, a carta branca concedida a cerca de cinco milhões de perfis, considerados usuários VIP, para os quais simplesmente não existiriam regras de moderação, como adiantou no mês passado o <i>The Wall Street Journal</i>. Entre os usuários importantes estariam conhecidos representantes da <i>alt-right</i> americana e do círculo mais próximo de Trump, como <a href=\"https://brasil.elpais.com/internacional/2021-01-20/trump-indulta-seu-ex-estrategista-steve-bannon-horas-antes-de-deixar-a-casa-branca.html\" target=\"_blank\">seu ex-estrategista Steve Bannon</a>, assim como blogueiros e portais <i>informativos</i> em sua órbita.</p>","<p>A hipotética rédea solta dada pelo Facebook —quase sempre em favor de políticos e posicionamentos conservadores, como demonstram os casos dos EUA e da Índia— ganha um caráter mais perigoso em países onde o risco de instabilidade e violência é real. Em uma análise publicada no ano passado no fórum de discussão interno sobre os métodos para identificar excessos, um funcionário relatou “brechas significativas” especialmente em Mianmar —o papel do Facebook na propagação do discurso de ódio que impulsionou o genocídio rohingya foi demonstrado já 2018— e na Etiópia, onde uma de suas regiões, Tigray, vive um conflito civil cada vez mais sangrento. A triagem feita pelos algoritmos “classificadores”, que detectam conteúdo inadequado, revelou-se inútil no escrutínio de mensagens nos idiomas ou dialetos falados na antiga Birmânia e na Etiópia; neste caso, com abundantes ameaças de morte.</p>","<p>As brechas de segurança do Facebook se resumem em quatro: a <a href=\"https://brasil.elpais.com/ciencia/2021-07-28/em-95-dos-artigos-cientificos-ingles-cria-ditadura-da-lingua-apenas-1-esta-em-portugues-e-espanhol.html\" target=\"_blank\">incapacidade linguística de entender</a>, e consequentemente de moderar, milhões de publicações de usuários em países de língua não inglesa; a incompreensão de seus próprios algoritmos; a inação na hora de intervir onde os programas de inteligência artificial não chegam (segundo um relatório de março, a empresa só adota medidas em 3% a 5% dos casos de discursos de ódio, e em 0,6% das publicações de conteúdo violento); e uma evidente negligência às vésperas do ataque ao Capitólio; na verdade, o Facebook desativou certas salvaguardas de emergência impostas para as eleições de novembro de 2020 nos EUA, e precisou reativar rapidamente algumas delas quando explodiu a violência em 6 de janeiro. A incapacidade de lidar com a <a href=\"https://brasil.elpais.com/internacional/2021-01-18/os-patriotas-que-invadiram-o-congresso-dos-estados-unidos.html\" target=\"_blank\">atividade <i>on-line</i> das hordas trumpistas</a> causou mal-estar no seio da empresa.</p>","<p>Os documentos vazados fazem parte da <a href=\"https://brasil.elpais.com/tecnologia/2021-10-10/a-informante-que-levou-o-facebook-a-sua-pior-crise-existencial.html\" target=\"_blank\">denúncia de Frances Haugen, ex-executiva do Facebook</a>, gigante de tecnologia que superou mais rapidamente —em apenas 17 anos— a marca de um trilhão de dólares (5,58 trilhões de reais) em valor de mercado, segundo a Bloomberg. Haugen compareceu na segunda-feira a uma comissão do Parlamento britânico, duas semanas depois de prestar depoimento no Congresso dos EUA. Porta-vozes do Facebook tentaram minimizar o golpe para sua reputação dizendo, em um comunicado, <a href=\"https://brasil.elpais.com/tecnologia/2021-10-06/zuckerberg-nao-e-verdade-que-para-nos-o-lucro-esteja-acima-do-bem-estar-dos-usuarios.html\" target=\"_blank\">que a empresa nunca colocou o lucro acima da segurança</a> ou do bem-estar das pessoas. Pelo contrário, “investimos 13 bilhões [de dólares, 72,6 bilhões de reais] e temos mais de 40.000 funcionários dedicados apenas a uma coisa: garantir a segurança das pessoas no Facebook”.</p>","<p>O orçamento das grandes empresas de <i>software</i>, <i>hardware</i> e serviços de inteligência artificial pode chegar a 342 bilhões de dólares (1,9 trilhão de reais) neste ano, segundo a International Data Corp. Esses gastos em IA devem passar de 500 bilhões de dólares (2,79 trilhões de reais) em 2024, segundo a mesma fonte.</p>","<p>As denúncias de Haugen e de outros ex-funcionários do Facebook colocam esse gigante da tecnologia diante de seus demônios, depois de ter conseguido superar parcialmente <a href=\"https://brasil.elpais.com/economia/2020-12-09/estados-unidos-processam-facebook-por-monopolio.html\" target=\"_blank\">uma ofensiva judicial por práticas monopolistas</a>. Assim como, em outra época, as empresas de tabaco dos EUA e a farmacêutica responsável pela crise de opioides por suas campanhas agressivas de <i>marketing</i> —e pela falsa afirmação de que o fármaco não causava dependência—, o Facebook parece, segundo as informações vazadas, ter priorizado a monetização sem dotá-la de salvaguardas. Parece ter desprezado a segurança, até mesmo a integridade física de muitas pessoas, para ganhar dinheiro. Segundo o ex-diretor para Oriente Médio e Norte da África, os objetivos de crescimento global eram “coloniais”, no sentido de favorecer a qualquer custo a hegemonia e o domínio sobre milhões de súditos digitais. Mais de 90% dos usuários ativos do Facebook vivem fora dos EUA e Canadá.</p>","<p><i>Inscreva-se </i><a href=\"https://plus.elpais.com/newsletters/lnp/3/375/\"><i>aqui</i></a><i> para receber a newsletter diária do EL PAÍS Brasil: reportagens, análises, entrevistas exclusivas e as principais informações do dia no seu e-mail, de segunda a sexta. </i><a href=\"https://plus.elpais.com/newsletters/?cp=3\"><i>Inscreva-se</i></a><i> também para receber nossa newsletter semanal aos sábados, com os destaques da cobertura na semana.</i></p>"],"textContent":"Frances Haugen na segunda-feira em Londres, durante depoimento a uma comissão do Parlamento britânico.DPA vía Europa Press  (Europa Press)O Facebook se tornou um aprendiz de feiticeiro cujo sucesso fugiu de seu controle. A revelação de documentos internos da rede social segundo os quais seus executivos permitiram, por ação ou omissão, a publicação de desinformação e conteúdo polêmico se voltou como um bumerangue contra a empresa. Essas informações provocaram a pior crise de reputação de sua história, que já incluía episódios obscuros sobre a privacidade dos dados, como o caso da Cambridge Analytica.Assim como as empresas de tabaco em outra época, ou como a farmacêutica que fabricou o medicamento responsável pela grave crise de opioides nos EUA —todas negando a possibilidade de vício—, o Facebook enfrenta o grande momento da verdade: depois da idílica comunidade global que pretendeu criar, ele contribuiu para prejudicar a convivência por ignorar conteúdo potencialmente violento, como discursos de ódio em países onde essas mensagens podem ter graves consequências, pelo que indicam os documentos revelados.A constatação da negligência não se aplica apenas aos EUA de Donald Trump —com o auge das fake news graças às redes sociais, e consequências como o ataque ao Capitólio em 6 de janeiro— ou à porcentagem ainda pequena de vacinação contra a covid-19 por culpa de teorias não científicas que o Facebook ajudou a fomentar. A falta de controle da empresa sobre seus conteúdos também causou estragos na Índia, ao potencializar a política de nova hinduização do país por parte do nacionalista Narendra Modi. E em Mianmar, atiçando a perseguição contra a comunidade rohingya. E também no Afeganistão, no Iêmen, na Etiópia.Isso se depreende do último conjunto de documentos internos vazados para um consórcio de veículos de comunicação internacionais, os chamados Facebook Papers. Uma questão central é determinar se o próprio funcionamento da plataforma deu origem ao problema; ou seja, se as ferramentas que tornaram o Facebook aquilo que ele é hoje —os botões de curtir e de compartilhar conteúdo, tão intuitivos— multiplicaram exponencialmente o risco na ausência de uma moderação adequada das publicações.As revelações, baseadas em entrevistas com ex-funcionários e relatórios internos, mostram como a expansão global da empresa —presente em mais de 190 países e mais de 160 idiomas, com mais de 2,8 bilhões de usuários por mês— negligenciou o controle do conteúdo por causa, em muitos casos, de um número insuficiente de moderadores com conhecimento adequado dos idiomas e contextos locais para identificar publicações potencialmente perigosas —ou no mínimo duvidosas— em muitos países em desenvolvimento. Em 2019, além disso, a empresa reduziu seu orçamento para a contratação de moderadores, em prol das máquinas.Os vazamentos também revelam que os sistemas de inteligência artificial (IA) usados pelo Facebook para evitar esse tipo de conteúdo são, muitas vezes, ineficazes, assim como as ferramentas para o possível aviso de um usuário. A descrição mostra um Facebook hipoteticamente blindado contra as denúncias, ao que se soma, além disso, a carta branca concedida a cerca de cinco milhões de perfis, considerados usuários VIP, para os quais simplesmente não existiriam regras de moderação, como adiantou no mês passado o The Wall Street Journal. Entre os usuários importantes estariam conhecidos representantes da alt-right americana e do círculo mais próximo de Trump, como seu ex-estrategista Steve Bannon, assim como blogueiros e portais informativos em sua órbita.A hipotética rédea solta dada pelo Facebook —quase sempre em favor de políticos e posicionamentos conservadores, como demonstram os casos dos EUA e da Índia— ganha um caráter mais perigoso em países onde o risco de instabilidade e violência é real. Em uma análise publicada no ano passado no fórum de discussão interno sobre os métodos para identificar excessos, um funcionário relatou “brechas significativas” especialmente em Mianmar —o papel do Facebook na propagação do discurso de ódio que impulsionou o genocídio rohingya foi demonstrado já 2018— e na Etiópia, onde uma de suas regiões, Tigray, vive um conflito civil cada vez mais sangrento. A triagem feita pelos algoritmos “classificadores”, que detectam conteúdo inadequado, revelou-se inútil no escrutínio de mensagens nos idiomas ou dialetos falados na antiga Birmânia e na Etiópia; neste caso, com abundantes ameaças de morte.As brechas de segurança do Facebook se resumem em quatro: a incapacidade linguística de entender, e consequentemente de moderar, milhões de publicações de usuários em países de língua não inglesa; a incompreensão de seus próprios algoritmos; a inação na hora de intervir onde os programas de inteligência artificial não chegam (segundo um relatório de março, a empresa só adota medidas em 3% a 5% dos casos de discursos de ódio, e em 0,6% das publicações de conteúdo violento); e uma evidente negligência às vésperas do ataque ao Capitólio; na verdade, o Facebook desativou certas salvaguardas de emergência impostas para as eleições de novembro de 2020 nos EUA, e precisou reativar rapidamente algumas delas quando explodiu a violência em 6 de janeiro. A incapacidade de lidar com a atividade on-line das hordas trumpistas causou mal-estar no seio da empresa.Os documentos vazados fazem parte da denúncia de Frances Haugen, ex-executiva do Facebook, gigante de tecnologia que superou mais rapidamente —em apenas 17 anos— a marca de um trilhão de dólares (5,58 trilhões de reais) em valor de mercado, segundo a Bloomberg. Haugen compareceu na segunda-feira a uma comissão do Parlamento britânico, duas semanas depois de prestar depoimento no Congresso dos EUA. Porta-vozes do Facebook tentaram minimizar o golpe para sua reputação dizendo, em um comunicado, que a empresa nunca colocou o lucro acima da segurança ou do bem-estar das pessoas. Pelo contrário, “investimos 13 bilhões [de dólares, 72,6 bilhões de reais] e temos mais de 40.000 funcionários dedicados apenas a uma coisa: garantir a segurança das pessoas no Facebook”.O orçamento das grandes empresas de software, hardware e serviços de inteligência artificial pode chegar a 342 bilhões de dólares (1,9 trilhão de reais) neste ano, segundo a International Data Corp. Esses gastos em IA devem passar de 500 bilhões de dólares (2,79 trilhões de reais) em 2024, segundo a mesma fonte.As denúncias de Haugen e de outros ex-funcionários do Facebook colocam esse gigante da tecnologia diante de seus demônios, depois de ter conseguido superar parcialmente uma ofensiva judicial por práticas monopolistas. Assim como, em outra época, as empresas de tabaco dos EUA e a farmacêutica responsável pela crise de opioides por suas campanhas agressivas de marketing —e pela falsa afirmação de que o fármaco não causava dependência—, o Facebook parece, segundo as informações vazadas, ter priorizado a monetização sem dotá-la de salvaguardas. Parece ter desprezado a segurança, até mesmo a integridade física de muitas pessoas, para ganhar dinheiro. Segundo o ex-diretor para Oriente Médio e Norte da África, os objetivos de crescimento global eram “coloniais”, no sentido de favorecer a qualquer custo a hegemonia e o domínio sobre milhões de súditos digitais. Mais de 90% dos usuários ativos do Facebook vivem fora dos EUA e Canadá.Inscreva-se aqui para receber a newsletter diária do EL PAÍS Brasil: reportagens, análises, entrevistas exclusivas e as principais informações do dia no seu e-mail, de segunda a sexta. Inscreva-se também para receber nossa newsletter semanal aos sábados, com os destaques da cobertura na semana.","length":7655,"excerpt":"Revelação jornalística de relatórios internos sobre a insuficiência da moderação humana e automática de milhões de publicações provoca a crise de reputação mais grave da empresa","siteName":"El País Brasil","image":"https://imagens.brasil.elpais.com/resizer/CrsZ-I17vU8TKvS58wXYyom-D_0=/1200x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg","url":"https://brasil.elpais.com/economia/2021-10-26/facebook-tolerou-discursos-de-odio-em-paises-em-guerra-em-prol-de-seu-crescimento.html"},"es-es":{"title":"Facebook toleró contenido potencialmente violento, como discursos de odio en países en guerra, en aras de su crecimiento","byline":"María Antonia Sánchez-Vallejo","content":["<figure><span><img alt=\"Frances Haugen (derecha) comparece este lunes ante un comité del Parlamento británico en Londres.\" decoding=\"auto\" height=\"276\" srcset=\"https://imagenes.elpais.com/resizer/2KGiln5xrY4U8Yflslcc8_3wpyU=/414x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg 414w,https://imagenes.elpais.com/resizer/BqHGUzBOcR1EMAJ7LeNAzxwxn7g=/828x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg 640w,https://imagenes.elpais.com/resizer/HTPrw0YeAUk0_v7bMCECvFpsal4=/980x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg 1000w,https://imagenes.elpais.com/resizer/tbMG8jR7KhrQP0RCS0wJmXpdzRs=/1960x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg 1960w\" width=\"414\" loading=\"lazy\" src=\"https://imagenes.elpais.com/resizer/2KGiln5xrY4U8Yflslcc8_3wpyU=/414x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg\"/></span><figcaption><span>Frances Haugen (derecha) comparece este lunes ante un comité del Parlamento británico en Londres.</span><span>DPA vía Europa Press  (Europa Press)</span></figcaption></figure>","<p>Facebook se ha convertido en un aprendiz de brujo al que el éxito se le va de las manos. La revelación de documentos internos de la red social según los cuales sus ejecutivos permitieron por acción u omisión la publicación de desinformación y contenido polémico se ha vuelto como un bumerán contra la compañía. Estas informaciones le han ocasionado la peor crisis de reputación de su historia, que ya acarreaba episodios oscuros en torno a la privacidad de los datos como <a href=\"https://elpais.com/noticias/caso-cambridge-analytica/\">el de <i>Cambridge Analytica</i></a>.</p>","<p>Igual que las tabacaleras en su día, o la farmacéutica que fabricó el medicamento responsable de la grave crisis de opioides en EE UU ―todas negando la posibilidad de la adicción―, Facebook se enfrenta al gran momento de la verdad: el de que, tras la idílica comunidad global que ha pretendido crear, ha contribuido a dañar la convivencia por ignorar <a href=\"https://elpais.com/tecnologia/2020-06-26/facebook-asegura-que-controlara-el-discurso-del-odio-tras-la-decision-de-unilever-de-retirar-la-publicidad.html\">contenido potencialmente violento como discursos de odio</a> en países donde esos mensajes pueden tener graves consecuencias, según se desprende de las revelaciones de documentos.</p>","<p>La constatación del descuido no sólo se aplica a los EE UU de Donald Trump, <a href=\"https://elpais.com/internacional/2017/05/06/estados_unidos/1494087975_053461.html\">con el apogeo de las <i>fake news</i> gracias a las redes sociales</a> y consecuencias tales como <a href=\"https://elpais.com/especiales/2021/reconstruccion-visual-del-asalto-al-capitolio/\">el asalto al Capitolio del 6 de enero</a>, o el aún reducido porcentaje de vacunación contra la covid-19 <a href=\"https://elpais.com/sociedad/2021-10-10/un-bulo-sobre-la-covid-agota-un-medicamento-para-caballos-en-estados-unidos.html\">por culpa de teorías acientíficas</a> a las que Facebook ha contribuido a dar pábulo. La falta de control de la tecnológica sobre sus contenidos también ha hecho estragos en la India, al potenciar la política de <i>rehinduificación</i> del país por parte del nacionalista Narendra Modi. O en Myanmar, atizando la persecución de <a href=\"https://elpais.com/noticias/rohinyas/\">la comunidad rohinyá</a>. También en Afganistán, Yemen o Etiopía.</p>","<p>Así se desprende de la última tanda de documentos internos filtrados a un consorcio de medios internacionales, conocidos ya como los <i>papeles Facebook</i>. Un tema central es determinar si el propio funcionamiento de la plataforma ha originado el problema; es decir, si las herramientas que han hecho de Facebook lo que es ―el botón de <i>like</i> y el de compartir contenido, tan intuitivos― han multiplicado exponencialmente el riesgo <a href=\"https://elpais.com/tecnologia/2020-05-06/facebook-crea-su-tribunal-supremo.html\">en ausencia de una adecuada moderación de las publicaciones</a>.</p>","<p>Las revelaciones, basadas en entrevistas a antiguos empleados e informes internos, constatan cómo la expansión global de la compañía ―presente en más de 190 países y más de 160 idiomas, con más de 2.800 millones de usuarios al mes― descuidó el control del contenido a causa, en muchos casos, de un número insuficiente de moderadores con adecuado conocimiento del idioma y el contexto locales para identificar publicaciones potencialmente peligrosas ―o cuando menos dudosas― en numerosos países en desarrollo; en 2019, además, la empresa recortó su presupuesto para contratar a moderadores, en favor de las máquinas.</p>","<p>Las filtraciones también revelan que los sistemas de inteligencia artificial (IA) que Facebook emplea para impedir dicho contenido a menudo no son eficaces, pero tampoco las herramientas para el posible aviso de un usuario. La descripción arroja un Facebook hipotéticamente blindado a las denuncias, al que se suma, además, la carta blanca concedida <a href=\"https://elpais.com/tecnologia/2021-09-15/facebook-admite-en-documentos-internos-que-instagram-perjudica-la-autoestima-de-muchas-jovenes.html\">a unos cinco millones de perfiles, considerados usuarios VIP</a>, para los que las reglas de moderación sencillamente no existirían, como adelantó el mes pasado el diario <i>The Wall Street Journal</i>. Entre los usuarios importantes se hallarían conspicuos representantes de <a href=\"https://elpais.com/internacional/2016/11/21/estados_unidos/1479765598_617726.html\">la <i>alt righ</i> estadounidense</a> y del círculo más íntimo de Trump, como quien fuera su estratega, <a href=\"https://elpais.com/internacional/2019/03/24/actualidad/1553454729_290547.html\">Steve Bannon</a>, y conocidos blogueros y portales <i>informativos</i> en su órbita.</p>","<p>La hipotética manga ancha de Facebook -casi siempre en favor de políticos y planteamientos conservadores, como demuestran los casos de EE UU y la India- adquiere un carácter más peliagudo en países donde el riesgo de la inestabilidad y la violencia es real. En una revisión publicada el año pasado en el foro de mensajes interno sobre los métodos para identificar excesos, un empleado informó de “brechas significativas” especialmente en Myanmar -el papel de Facebook propalando <a href=\"https://elpais.com/internacional/2018/04/12/actualidad/1523553344_423934.html\">el discurso de odio que azuzó el genocidio rohinyá se demostró ya en 2018</a>- y Etiopía, una de cuyas regiones, Tigray, vive un conflicto civil cada vez más cruento. La criba de los algoritmos “clasificadores”, que detectan contenido inadecuado, se reveló inútil en el escrutinio de mensajes en los idiomas o dialectos hablados en la antigua Birmania o Etiopía; en este caso, con abundantes amenazas de muerte.</p>","<p>Las brechas de seguridad de Facebook se resumen en cuatro: la incapacidad lingüística de entender, y por ende moderar, millones de publicaciones de usuarios en países de habla no inglesa; la incomprensión de sus propios algoritmos; la inacción a la hora de intervenir allí donde los programas de IA no llegan (según un informe de marzo, la compañía sólo adopta medidas entre el 3% y el 5% de los casos de discursos de odio, y en el 0,6% de las publicaciones de contenido violento); y <a href=\"https://elpais.com/tecnologia/2021-03-25/las-tecnologicas-reconocen-ante-el-congreso-que-jugaron-un-papel-crucial-en-el-asalto-al-capitolio.html\">un palpable descuido, desidia incluso, en vísperas del asalto al Capitolio</a>; de hecho, la compañía desactivó <a href=\"https://elpais.com/tecnologia/2020-11-06/facebook-cierra-un-grupo-con-320000-seguidores-que-alegaba-fraude-electoral-en-ee-uu-e-incitaba-a-la-violencia.html\">ciertas salvaguardas de emergencia impuestas para las elecciones de noviembre de 2020</a>, y tuvo que activar rápidamente algunas cuando la violencia estalló el 6 de enero. La incapacidad de abordar la actividad <i>online</i> de las hordas trumpistas causó malestar en el seno de la compañía.</p>","<p>Los documentos filtrados pertenecen a <a href=\"https://elpais.com/tecnologia/2021-10-10/la-garganta-profunda-que-llevo-a-facebook-a-su-peor-crisis-existencial.html\">la confesión de Frances Haugen</a>, exejecutiva de Facebook, el gigante tecnológico que más rápidamente -en solo 17 años- ha superado la cota del billón de dólares de valor de mercado, según Bloomberg. Haugen ha comparecido este lunes ante un comité del Parlamento británico, dos semanas <a href=\"https://elpais.com/tecnologia/2021-10-04/la-garganta-profunda-de-facebook-da-la-cara-financian-sus-beneficios-con-nuestra-seguridad.html\">después de hacerlo ante el Congreso de EE UU</a>. Portavoces de la compañía han intentado minimizar el golpe a su reputación subrayando, en un comunicado, que nunca ha puesto el beneficio por delante de la seguridad o el bienestar de la gente. Antes, al contrario, “hemos invertido 13.000 millones [de dólares] y tenemos más de 40.000 empleados dedicados solo a una cosa: garantizar la seguridad de la gente en Facebook”.</p>","<p>El presupuesto de las grandes tecnológicas en <i>software</i>, <i>hardware</i> y servicios de IA podría alcanzar los 342.000 millones de dólares este año, según International Data Corp. Dicho gasto en IA va camino de superar el listón de los 500.000 millones en 2024, según la misma fuente.</p>","<p>La confesión de Haugen y el resto de exempleados de Facebook coloca al gigante tecnológico frente a sus demonios, <a href=\"https://cincodias.elpais.com/cincodias/2021/06/29/companias/1624921958_916613.html\">tras haber podido remontar en parte una ofensiva judicial por prácticas monopolísticas</a>. Igual que en su día las tabacaleras de EE UU, o la farmacéutica responsable de la crisis de opioides por sus agresivas campañas de marketing -y el engaño manifiesto de que el fármaco no causaba adicción-, Facebook parece, según la información filtrada, haber priorizado la monetización sin dotarla de salvaguardas; despreciado la seguridad -incluso la integridad física de muchas personas- por hacer caja. Según el exresponsable para Oriente Próximo y Norte de África, los objetivos de crecimiento global fueron “coloniales”, en el sentido de favorecer a cualquier precio la hegemonía y el dominio sobre millones de <i>súbditos</i> digitales. Más del 90% de los usuarios activos de Facebook viven fuera de EE UU y Canadá.</p>"],"textContent":"Frances Haugen (derecha) comparece este lunes ante un comité del Parlamento británico en Londres.DPA vía Europa Press  (Europa Press)Facebook se ha convertido en un aprendiz de brujo al que el éxito se le va de las manos. La revelación de documentos internos de la red social según los cuales sus ejecutivos permitieron por acción u omisión la publicación de desinformación y contenido polémico se ha vuelto como un bumerán contra la compañía. Estas informaciones le han ocasionado la peor crisis de reputación de su historia, que ya acarreaba episodios oscuros en torno a la privacidad de los datos como el de Cambridge Analytica.Igual que las tabacaleras en su día, o la farmacéutica que fabricó el medicamento responsable de la grave crisis de opioides en EE UU ―todas negando la posibilidad de la adicción―, Facebook se enfrenta al gran momento de la verdad: el de que, tras la idílica comunidad global que ha pretendido crear, ha contribuido a dañar la convivencia por ignorar contenido potencialmente violento como discursos de odio en países donde esos mensajes pueden tener graves consecuencias, según se desprende de las revelaciones de documentos.La constatación del descuido no sólo se aplica a los EE UU de Donald Trump, con el apogeo de las fake news gracias a las redes sociales y consecuencias tales como el asalto al Capitolio del 6 de enero, o el aún reducido porcentaje de vacunación contra la covid-19 por culpa de teorías acientíficas a las que Facebook ha contribuido a dar pábulo. La falta de control de la tecnológica sobre sus contenidos también ha hecho estragos en la India, al potenciar la política de rehinduificación del país por parte del nacionalista Narendra Modi. O en Myanmar, atizando la persecución de la comunidad rohinyá. También en Afganistán, Yemen o Etiopía.Así se desprende de la última tanda de documentos internos filtrados a un consorcio de medios internacionales, conocidos ya como los papeles Facebook. Un tema central es determinar si el propio funcionamiento de la plataforma ha originado el problema; es decir, si las herramientas que han hecho de Facebook lo que es ―el botón de like y el de compartir contenido, tan intuitivos― han multiplicado exponencialmente el riesgo en ausencia de una adecuada moderación de las publicaciones.Las revelaciones, basadas en entrevistas a antiguos empleados e informes internos, constatan cómo la expansión global de la compañía ―presente en más de 190 países y más de 160 idiomas, con más de 2.800 millones de usuarios al mes― descuidó el control del contenido a causa, en muchos casos, de un número insuficiente de moderadores con adecuado conocimiento del idioma y el contexto locales para identificar publicaciones potencialmente peligrosas ―o cuando menos dudosas― en numerosos países en desarrollo; en 2019, además, la empresa recortó su presupuesto para contratar a moderadores, en favor de las máquinas.Las filtraciones también revelan que los sistemas de inteligencia artificial (IA) que Facebook emplea para impedir dicho contenido a menudo no son eficaces, pero tampoco las herramientas para el posible aviso de un usuario. La descripción arroja un Facebook hipotéticamente blindado a las denuncias, al que se suma, además, la carta blanca concedida a unos cinco millones de perfiles, considerados usuarios VIP, para los que las reglas de moderación sencillamente no existirían, como adelantó el mes pasado el diario The Wall Street Journal. Entre los usuarios importantes se hallarían conspicuos representantes de la alt righ estadounidense y del círculo más íntimo de Trump, como quien fuera su estratega, Steve Bannon, y conocidos blogueros y portales informativos en su órbita.La hipotética manga ancha de Facebook -casi siempre en favor de políticos y planteamientos conservadores, como demuestran los casos de EE UU y la India- adquiere un carácter más peliagudo en países donde el riesgo de la inestabilidad y la violencia es real. En una revisión publicada el año pasado en el foro de mensajes interno sobre los métodos para identificar excesos, un empleado informó de “brechas significativas” especialmente en Myanmar -el papel de Facebook propalando el discurso de odio que azuzó el genocidio rohinyá se demostró ya en 2018- y Etiopía, una de cuyas regiones, Tigray, vive un conflicto civil cada vez más cruento. La criba de los algoritmos “clasificadores”, que detectan contenido inadecuado, se reveló inútil en el escrutinio de mensajes en los idiomas o dialectos hablados en la antigua Birmania o Etiopía; en este caso, con abundantes amenazas de muerte.Las brechas de seguridad de Facebook se resumen en cuatro: la incapacidad lingüística de entender, y por ende moderar, millones de publicaciones de usuarios en países de habla no inglesa; la incomprensión de sus propios algoritmos; la inacción a la hora de intervenir allí donde los programas de IA no llegan (según un informe de marzo, la compañía sólo adopta medidas entre el 3% y el 5% de los casos de discursos de odio, y en el 0,6% de las publicaciones de contenido violento); y un palpable descuido, desidia incluso, en vísperas del asalto al Capitolio; de hecho, la compañía desactivó ciertas salvaguardas de emergencia impuestas para las elecciones de noviembre de 2020, y tuvo que activar rápidamente algunas cuando la violencia estalló el 6 de enero. La incapacidad de abordar la actividad online de las hordas trumpistas causó malestar en el seno de la compañía.Los documentos filtrados pertenecen a la confesión de Frances Haugen, exejecutiva de Facebook, el gigante tecnológico que más rápidamente -en solo 17 años- ha superado la cota del billón de dólares de valor de mercado, según Bloomberg. Haugen ha comparecido este lunes ante un comité del Parlamento británico, dos semanas después de hacerlo ante el Congreso de EE UU. Portavoces de la compañía han intentado minimizar el golpe a su reputación subrayando, en un comunicado, que nunca ha puesto el beneficio por delante de la seguridad o el bienestar de la gente. Antes, al contrario, “hemos invertido 13.000 millones [de dólares] y tenemos más de 40.000 empleados dedicados solo a una cosa: garantizar la seguridad de la gente en Facebook”.El presupuesto de las grandes tecnológicas en software, hardware y servicios de IA podría alcanzar los 342.000 millones de dólares este año, según International Data Corp. Dicho gasto en IA va camino de superar el listón de los 500.000 millones en 2024, según la misma fuente.La confesión de Haugen y el resto de exempleados de Facebook coloca al gigante tecnológico frente a sus demonios, tras haber podido remontar en parte una ofensiva judicial por prácticas monopolísticas. Igual que en su día las tabacaleras de EE UU, o la farmacéutica responsable de la crisis de opioides por sus agresivas campañas de marketing -y el engaño manifiesto de que el fármaco no causaba adicción-, Facebook parece, según la información filtrada, haber priorizado la monetización sin dotarla de salvaguardas; despreciado la seguridad -incluso la integridad física de muchas personas- por hacer caja. Según el exresponsable para Oriente Próximo y Norte de África, los objetivos de crecimiento global fueron “coloniales”, en el sentido de favorecer a cualquier precio la hegemonía y el dominio sobre millones de súbditos digitales. Más del 90% de los usuarios activos de Facebook viven fuera de EE UU y Canadá.","length":7370,"excerpt":"La revelación periodística de informes internos sobre la insuficiente moderación humana e informática de millones de publicaciones provoca la crisis de reputación más grave de la tecnológica","siteName":"El País","image":"https://imagenes.elpais.com/resizer/CrsZ-I17vU8TKvS58wXYyom-D_0=/1200x0/filters:focal(1217x409:1227x419)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/NNZGNQBCDD6EELHCK4BX7QB5YE.jpg","url":"https://elpais.com/economia/2021-10-25/facebook-ignoro-contenido-potencialmente-violento-como-discursos-de-odio-en-paises-en-guerra-en-aras-de-su-crecimiento.html"}}},"__N_SSG":true}