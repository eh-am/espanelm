{"pageProps":{"page":{"id":"44cada5ae51c59f1b1db39611397c8bf","pt-br":{"title":"Algoritmo do Twitter prefere rostos femininos, brancos e magros, demonstram programadores em desafio","byline":"Jordi Pérez Colomé","content":["<p>Em setembro de 2020, um aluno da Universidade de Victoria (Canadá) descobriu sem querer que o <a href=\"https://brasil.elpais.com/noticias/twitter/\" target=\"_blank\">Twitter </a>dava mais destaque aos rostos brancos ao recortar fotos. Seus tuítes sobre o assunto provocaram uma grande polêmica, e dezenas de outros tuiteiros apresentaram provas no mesmo  sentido. Finalmente, a rede social decidiu averiguar o que ocorria. O  processo terminou neste mês de agosto com uma competição ―a primeira do  tipo― entre informáticos que foram autorizados a analisar o algoritmo,  disputando uma recompensa por suas descobertas. O desafio confirmou que  algum viés existia. <a href=\"https://github.com/bogdan-kulynych/saliency_bias\" target=\"_blank\">O vencedor, Bogdan Kulynych (Ucrânia, 1993)</a>, doutorando da Universidade Politécnica de Lausanne (Suíça), descobriu  que certamente o algoritmo prefere rostos claros, jovens, magros e com traços femininos.</p>","<p>O viés <a href=\"https://brasil.elpais.com/noticias/algoritmos-computacionales/\" target=\"_blank\">dos algoritmos</a> não é nenhuma novidade. Um algoritmo desse tipo é um software que ordena resultados a partir de dados previamente apresentados. No caso do Twitter, ele escolhia o fragmento (os pixels)  de uma imagem que considerava mais interessante, destacando-a na  interface dos usuários.</p>","<section><h3>Mais informações </h3></section>","<p>Este algoritmo provém de um modelo elaborado a  partir do monitoramento do olhar humano quando uma imagem aparece em uma tela. E supostamente os humanos preferem rostos de pele clara,  femininos, magros, jovens e com um tom quente e bem contrastado. <a href=\"https://arxiv.org/pdf/2105.08667.pdf\" target=\"_blank\">Em um estudo feito pelo próprio Twitter antes do concurso</a>, quando já se notava um viés, foi analisado também se há um “olhar masculino”: às vezes o  algoritmo se centrava em outras zonas do corpo feminino além do rosto, e  segundo o artigo científico que acompanhava o estudo isso refletia a  “representação constante das mulheres como objetos sexuais para o prazer  sob o ponto de vista dos homens heterossexuais”.</p>","<p> “Na minha pesquisa gerei vários rostos artificiais e os modifiquei não arbitrariamente, mas sim de uma maneira muito específica para ver a quais deles o algoritmo  dava mais proeminência”, diz Kulynych ao EL PAÍS por teleconferência. Em  outras palavras, ele quis entender por que, ao fazer um recorte  automático, o algoritmo tendia a conservar ou a destacar mais  determinados rostos. “Selecionei só um pequeno grupo de 16 rostos por  problemas de tempo e porque o processo computacional é longo. Eram  rostos diversos, e no final vi padrões. O algoritmo dava mais  proeminência a rostos mais jovens, magros, com tons mais quentes e traços femininos”, continua.</p>","<p>Embora a amostra de Kulynych seja pequena, porque a competição deixava apenas uma semana para o trabalho, ele acha provável que esse problema seja “fundamental” e ocorreria da  mesma forma com uma amostra maior de rostos. “Embora eu suspeite que com essa análise mais extensa a diferença seria menos pronunciada, ou que  os padrões seriam menos claros”, observa.</p>","<figure><img alt=\"Detalhe do projeto de Kulynych: aqui se vê como o algoritmo pontua progressivamente melhor as imagens da direita pela feminilidade e o tom de pele mais rosado.\" width=\"880\" height=\"391\" loading=\"lazy\" src=\"https://imagens.brasil.elpais.com/resizer/-NaD7j6LKffqVaEwrOSwem0bOKc=/414x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png\" srcset=\"https://imagens.brasil.elpais.com/resizer/-NaD7j6LKffqVaEwrOSwem0bOKc=/414x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png 414w,https://imagens.brasil.elpais.com/resizer/x_05Cmk5Swt1nafeRjkywSeE_xo=/828x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png 640w,https://imagens.brasil.elpais.com/resizer/sYvwyQ1LyYqc639W6JEI8jLAL2U=/980x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png 1000w,https://imagens.brasil.elpais.com/resizer/zazKtnLlZJS8eMJyzgB9YzyXLgA=/1960x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png 1960w\"/><figcaption><span>Detalhe do projeto de Kulynych: aqui se vê como o algoritmo pontua progressivamente melhor as imagens da direita pela feminilidade e o tom de pele mais rosado.</span></figcaption></figure>","<p>O concurso foi uma espécie de autopsia do algoritmo.<a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm\" target=\"_blank\"> O Twitter o havia eliminado em maio</a>, quando o substituiu por uma opção manual: agora, cada usuário pode dar destaque à parte que preferir nas imagens que publica. “É uma boa opção”, considera Kulynych. A supressão do algoritmo só elimina um pequeno problema. No fundo, ele já não era crucial, pois só  decidia quais partes de uma foto grande mostraria. Em estudos  anteriores, algumas feitas com sua orientadora, a engenheira espanhola  Carmela Troncoso, Kulynych <a href=\"https://arxiv.org/abs/1811.11293\" target=\"_blank\">analisou o impacto de outros algoritmos mais  importantes para as grandes empresa tecnológicas:</a> aqueles mais  essenciais, que decidem o que vemos no Twitter, YouTube, Amazon e  Airbnb. Que comportamentos eles podem estar promovendo para beneficiar  essas empresas?</p>","<p>Algoritmos deste tipo não costumam ficar disponíveis atualmente para que pesquisadores externos possam buscar erros ou  vieses, diz Kulynych. Eles são uma parte nevrálgica das empresas  tecnológicas: “Além dos erros, há os problemas nos algoritmos que  emergem devido à estrutura de incentivos e otimização de benefícios  dentro das companhias”, alerta o doutorando. “Com eles ninguém organiza  competições, porque não são erros como tais. Só podem ser resolvidos de  fora, e para isso seria necessário uma regulação para desafios como  mitigar a desinformação nas redes sociais e o aumento da gentrificação  em plataformas como o Airbnb. A capacidade de autorregulação destas  empresas é limitada”, acrescenta.</p>","<div>\n  <p>Apoie a produção de notícias como esta. Assine o EL PAÍS por 30 dias por 1 US$</p>\n  <p><a href=\"\nhttps://apiservices.krxd.net/click_tracker/track?kx_event_uid=NqJG0P8a&amp;kx_distribuidor=redaccion&amp;kx_origen=elpais&amp;kx_disciplina=editorial&amp;kx_formato=ctamedio&amp;_creatividad=maradona&amp;kx-_formato_creatividad=ctamedio_maradona&amp;kx_landing_destino=BRASIL&amp;clk=https://brasil.elpais.com/assinaturas/#/campaign?prm=elpais_redaccion_epmas_editorial_ctamedio_maradona_BRASIL\">Clique aqui</a>\n</p></div>","<p>A competição do Twitter para  analisar seu algoritmo caído em desgraça é louvável, admite Kulynych, mas resta ver se será um primeiro passo ou simplesmente um caso isolado.  Rumman Chowdhury, nova diretora (incorporou-se em fevereiro) de Ética  do Aprendizado de Máquinas do Twitter, disse que não é fácil abrir o  algoritmo de recomendação do Twitter para que seja analisado de fora,  mas “seria fascinante fazer uma competição sobre vieses de sistemas”.</p>","<p>Em seu discurso sobre esta competição, Chowdhury admitiu a obviedade de  que o viés dos algoritmos se baseia em automatizar o que os humanos fazem de forma natural: “Criamos estes filtros porque acreditamos que  isso é o que é ‘bonito’, e isso termina treinando nossos modelos e nos  levando a estas noções irreais do que significa ser atraente”.</p>","<p>Em uma  conversa anterior no Twitter, funcionários da companhia fizeram uma  analogia para este concurso: lembra as primeiras recompensas dadas a  quem achava falhas de segurança nos softwares de anos atrás. Hoje em  dia, uma falha de segurança pode valer centenas de milhares ou milhões  de dólares, dependendo de quem a compre. Afinal, esse é um modo de  acessar sistemas sem ser detectado. Já Kulynych levou apenas 3.500  dólares (18.830 reais) por seu trabalho, o que é uma quantia irrisória  para os níveis do Vale do Silício.Mas talvez não pare por aí. “No  começo, as falhas de segurança eram relatadas e ninguém recebia nada em  troca, talvez o problema nem fosse arrumado. Assim nasceram as  recompensas, para criar um incentivo para comunicá-los aos criadores do  software e os arrumassem”, diz Kulynych. A diferença é que os problemas  de segurança podem ser revelados de fora, enquanto a análise do  algoritmo exige a cumplicidade da companhia, que precisa abri-lo a uma  análise externa.</p>","<p>O viés detectado por Kulynych não foi o único. O segundo prêmio foi para  um trabalho que também comprovava que o algoritmo prestava menos  atenção a rostos de idosos, e o terceiro coube a outro pesquisador que  descobriu, ao comparar memes com texto, que o algoritmo preferia a  linguagem em alfabeto latino em detrimento da escrita árabe. O Twitter  deu também um prêmio a um pesquisador italiano que descobriu que os  emojis de pele clara também recebem melhor pontuação do <a href=\"http://algoritmo.No\" target=\"_blank\">algoritmo. </a>No Brasil, a programadora <a href=\"https://www.ninadahora.dev/\" target=\"_blank\">Nina da Hora </a>trabalha para impedir que algoritmos reproduzam preconceitos. Ela busca formas para que a tecnologia seja mais justa e igualitária.</p>","<p><a href=\"https://suscripciones.elpais.com/para-conhecer/\"><i><b>Apoie nosso jornalismo. Assine o EL PAÍS clicando aqui</b></i></a></p>","<p><i>Inscreva-se </i><a href=\"https://plus.elpais.com/newsletters/lnp/3/375/\"><i>aqui</i></a><i> para receber a newsletter diária do EL PAÍS Brasil: reportagens, análises, entrevistas exclusivas e as principais informações do dia no seu e-mail, de segunda a sexta. </i><a href=\"https://plus.elpais.com/newsletters/?cp=3\"><i>Inscreva-se</i></a><i> também para receber nossa newsletter semanal aos sábados, com os destaques da cobertura na semana.</i></p>"],"textContent":"Em setembro de 2020, um aluno da Universidade de Victoria (Canadá) descobriu sem querer que o Twitter dava mais destaque aos rostos brancos ao recortar fotos. Seus tuítes sobre o assunto provocaram uma grande polêmica, e dezenas de outros tuiteiros apresentaram provas no mesmo  sentido. Finalmente, a rede social decidiu averiguar o que ocorria. O  processo terminou neste mês de agosto com uma competição ―a primeira do  tipo― entre informáticos que foram autorizados a analisar o algoritmo,  disputando uma recompensa por suas descobertas. O desafio confirmou que  algum viés existia. O vencedor, Bogdan Kulynych (Ucrânia, 1993), doutorando da Universidade Politécnica de Lausanne (Suíça), descobriu  que certamente o algoritmo prefere rostos claros, jovens, magros e com traços femininos.O viés dos algoritmos não é nenhuma novidade. Um algoritmo desse tipo é um software que ordena resultados a partir de dados previamente apresentados. No caso do Twitter, ele escolhia o fragmento (os pixels)  de uma imagem que considerava mais interessante, destacando-a na  interface dos usuários.Mais informações Este algoritmo provém de um modelo elaborado a  partir do monitoramento do olhar humano quando uma imagem aparece em uma tela. E supostamente os humanos preferem rostos de pele clara,  femininos, magros, jovens e com um tom quente e bem contrastado. Em um estudo feito pelo próprio Twitter antes do concurso, quando já se notava um viés, foi analisado também se há um “olhar masculino”: às vezes o  algoritmo se centrava em outras zonas do corpo feminino além do rosto, e  segundo o artigo científico que acompanhava o estudo isso refletia a  “representação constante das mulheres como objetos sexuais para o prazer  sob o ponto de vista dos homens heterossexuais”. “Na minha pesquisa gerei vários rostos artificiais e os modifiquei não arbitrariamente, mas sim de uma maneira muito específica para ver a quais deles o algoritmo  dava mais proeminência”, diz Kulynych ao EL PAÍS por teleconferência. Em  outras palavras, ele quis entender por que, ao fazer um recorte  automático, o algoritmo tendia a conservar ou a destacar mais  determinados rostos. “Selecionei só um pequeno grupo de 16 rostos por  problemas de tempo e porque o processo computacional é longo. Eram  rostos diversos, e no final vi padrões. O algoritmo dava mais  proeminência a rostos mais jovens, magros, com tons mais quentes e traços femininos”, continua.Embora a amostra de Kulynych seja pequena, porque a competição deixava apenas uma semana para o trabalho, ele acha provável que esse problema seja “fundamental” e ocorreria da  mesma forma com uma amostra maior de rostos. “Embora eu suspeite que com essa análise mais extensa a diferença seria menos pronunciada, ou que  os padrões seriam menos claros”, observa.Detalhe do projeto de Kulynych: aqui se vê como o algoritmo pontua progressivamente melhor as imagens da direita pela feminilidade e o tom de pele mais rosado.O concurso foi uma espécie de autopsia do algoritmo. O Twitter o havia eliminado em maio, quando o substituiu por uma opção manual: agora, cada usuário pode dar destaque à parte que preferir nas imagens que publica. “É uma boa opção”, considera Kulynych. A supressão do algoritmo só elimina um pequeno problema. No fundo, ele já não era crucial, pois só  decidia quais partes de uma foto grande mostraria. Em estudos  anteriores, algumas feitas com sua orientadora, a engenheira espanhola  Carmela Troncoso, Kulynych analisou o impacto de outros algoritmos mais  importantes para as grandes empresa tecnológicas: aqueles mais  essenciais, que decidem o que vemos no Twitter, YouTube, Amazon e  Airbnb. Que comportamentos eles podem estar promovendo para beneficiar  essas empresas?Algoritmos deste tipo não costumam ficar disponíveis atualmente para que pesquisadores externos possam buscar erros ou  vieses, diz Kulynych. Eles são uma parte nevrálgica das empresas  tecnológicas: “Além dos erros, há os problemas nos algoritmos que  emergem devido à estrutura de incentivos e otimização de benefícios  dentro das companhias”, alerta o doutorando. “Com eles ninguém organiza  competições, porque não são erros como tais. Só podem ser resolvidos de  fora, e para isso seria necessário uma regulação para desafios como  mitigar a desinformação nas redes sociais e o aumento da gentrificação  em plataformas como o Airbnb. A capacidade de autorregulação destas  empresas é limitada”, acrescenta.\n  Apoie a produção de notícias como esta. Assine o EL PAÍS por 30 dias por 1 US$\n  Clique aqui\nA competição do Twitter para  analisar seu algoritmo caído em desgraça é louvável, admite Kulynych, mas resta ver se será um primeiro passo ou simplesmente um caso isolado.  Rumman Chowdhury, nova diretora (incorporou-se em fevereiro) de Ética  do Aprendizado de Máquinas do Twitter, disse que não é fácil abrir o  algoritmo de recomendação do Twitter para que seja analisado de fora,  mas “seria fascinante fazer uma competição sobre vieses de sistemas”.Em seu discurso sobre esta competição, Chowdhury admitiu a obviedade de  que o viés dos algoritmos se baseia em automatizar o que os humanos fazem de forma natural: “Criamos estes filtros porque acreditamos que  isso é o que é ‘bonito’, e isso termina treinando nossos modelos e nos  levando a estas noções irreais do que significa ser atraente”.Em uma  conversa anterior no Twitter, funcionários da companhia fizeram uma  analogia para este concurso: lembra as primeiras recompensas dadas a  quem achava falhas de segurança nos softwares de anos atrás. Hoje em  dia, uma falha de segurança pode valer centenas de milhares ou milhões  de dólares, dependendo de quem a compre. Afinal, esse é um modo de  acessar sistemas sem ser detectado. Já Kulynych levou apenas 3.500  dólares (18.830 reais) por seu trabalho, o que é uma quantia irrisória  para os níveis do Vale do Silício.Mas talvez não pare por aí. “No  começo, as falhas de segurança eram relatadas e ninguém recebia nada em  troca, talvez o problema nem fosse arrumado. Assim nasceram as  recompensas, para criar um incentivo para comunicá-los aos criadores do  software e os arrumassem”, diz Kulynych. A diferença é que os problemas  de segurança podem ser revelados de fora, enquanto a análise do  algoritmo exige a cumplicidade da companhia, que precisa abri-lo a uma  análise externa.O viés detectado por Kulynych não foi o único. O segundo prêmio foi para  um trabalho que também comprovava que o algoritmo prestava menos  atenção a rostos de idosos, e o terceiro coube a outro pesquisador que  descobriu, ao comparar memes com texto, que o algoritmo preferia a  linguagem em alfabeto latino em detrimento da escrita árabe. O Twitter  deu também um prêmio a um pesquisador italiano que descobriu que os  emojis de pele clara também recebem melhor pontuação do algoritmo. No Brasil, a programadora Nina da Hora trabalha para impedir que algoritmos reproduzam preconceitos. Ela busca formas para que a tecnologia seja mais justa e igualitária.Apoie nosso jornalismo. Assine o EL PAÍS clicando aquiInscreva-se aqui para receber a newsletter diária do EL PAÍS Brasil: reportagens, análises, entrevistas exclusivas e as principais informações do dia no seu e-mail, de segunda a sexta. Inscreva-se também para receber nossa newsletter semanal aos sábados, com os destaques da cobertura na semana.","length":7352,"excerpt":"A rede social viveu uma polêmica há alguns meses pela forma que recortava as imagens. Agora uma competição em que venceu o doutorando ucraniano Bogdan Kulynych confirma as suspeitas","siteName":"EL PAÍS","image":"https://imagens.brasil.elpais.com/resizer/OBF3f4JTynO9QR9yVeBexLXNwHc=/1200x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/FELLXOTD4VFPLCPI5GUDLNOGWA.jpg","url":"https://brasil.elpais.com/tecnologia/2021-08-19/algoritmo-do-twitter-prefere-rostos-femininos-brancos-e-magros-demonstram-programadores-em-desafio.html"},"es-es":{"title":"El algoritmo de Twitter elegía caras femeninas, blancas y delgadas. Un concurso de programadores lo demostró","byline":"Jordi Pérez Colomé","content":["<p>En septiembre de 2020, un estudiante de la Universidad de Victoria (Canadá) descubrió sin querer que Twitter destacaba más los rostros blancos al recortar las imágenes. Su hilo de tuits provocó una gran polémica y decenas de pruebas de otros tuiteros en el mismo sentido. Finalmente Twitter decidió ver qué pasaba. El proceso ha culminado este mes de agosto con una competición ―la primera de este tipo― entre informáticos a quienes se permitió analizar el algoritmo. Y se les ofreció una recompensa por sus hallazgos. El concurso confirmó que algún sesgo existía. El vencedor, el doctorando de la Universidad Politécnica de Lausane (Suiza) <a href=\"https://github.com/bogdan-kulynych/saliency_bias\" target=\"_blank\">Bogdan Kulynych</a> (Ucrania, 1993) ha descubierto que ciertamente el algoritmo prefiere rostros claros, jóvenes, delgados y con rasgos femeninos.</p>","<p>El sesgo de los algoritmos <a href=\"https://elpais.com/eps/2021-06-27/cuando-el-algoritmo-se-equivoca.html\" target=\"_blank\">no es nada nuevo.</a> Un algoritmo de este tipo es un programa que ordena resultados a partir de datos que se le proporcionan. En el caso de Twitter escogía el fragmento (los píxeles) de una imagen que creía que iba a ser más interesante para destacarlo y que los usuarios de Twitter lo vieran en sus pantallas.</p>","<p>Este algoritmo proviene de un modelo elaborado a partir de seguir la mirada humana cuando aparece una imagen en una pantalla. Y supuestamente los humanos prefieren caras de piel clara, femeninas, delgadas, jóvenes, y con un tono cálido y bien contrastado. En un <a href=\"https://arxiv.org/pdf/2105.08667.pdf\" target=\"_blank\">estudio </a>previo al concurso que hizo la propia red social, y en el que ya se veía cierto sesgo, también analizaron lo que llaman la “mirada masculina”: a veces el algoritmo se centraba en zonas del cuerpo femenino que no eran la cara, lo que, según el artículo científico, se originaba en “la representación constante de las mujeres como objetos sexuales para el placer desde la perspectiva de los hombres heterosexuales”.</p>","<p>“En mi investigación generé varias caras artificiales y las modifiqué no arbitrariamente, sino de una manera muy específica para ver en cuáles el algoritmo incrementaba la prominencia”, explica Kulynych a EL PAÍS en una conversación por videoconferencia. Es decir, que cuando hacía un recorte automático, tendía a conservar o a destacar más dichos rostros. “Seleccioné solo un pequeño grupo de 16 caras por problemas de tiempo y porque el proceso computacional es largo. Eran caras diversas y al final vi patrones. El algoritmo daba más prominencia a caras más jóvenes, delgadas, con más calidez y rasgos femeninos”, continúa.</p>","<p>Aunque la muestra de Kulynych es pequeña porque la competición dejaba solo una semana para participar, cree que es probable que el problema fuera “fundamental” y ocurriera igual si se repitiera con una muestra de caras mayor. “Aunque sospecho que con ese análisis más extenso la diferencia sería menos pronunciada o que los patrones serían menos claros”, aclara.</p>","<figure><img alt=\"Detalle del proyecto de Kulynych: aquí se ve cómo el algoritmo puntúa progresivamente mejor las imágenes de la derecha por la feminidad y la calidez en el tono de la piel.\" width=\"880\" height=\"391\" loading=\"lazy\" src=\"https://imagenes.elpais.com/resizer/-NaD7j6LKffqVaEwrOSwem0bOKc=/414x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png\" srcset=\"https://imagenes.elpais.com/resizer/-NaD7j6LKffqVaEwrOSwem0bOKc=/414x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png 414w,https://imagenes.elpais.com/resizer/x_05Cmk5Swt1nafeRjkywSeE_xo=/828x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png 640w,https://imagenes.elpais.com/resizer/sYvwyQ1LyYqc639W6JEI8jLAL2U=/980x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png 1000w,https://imagenes.elpais.com/resizer/zazKtnLlZJS8eMJyzgB9YzyXLgA=/1960x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/3IUF5Q2DPZEOPGDBSJZQRBZGJQ.png 1960w\"/><figcaption><span>Detalle del proyecto de Kulynych: aquí se ve cómo el algoritmo puntúa progresivamente mejor las imágenes de la derecha por la feminidad y la calidez en el tono de la piel.</span></figcaption></figure>","<p>El concurso fue una especie de análisis <i>post mortem</i> del algoritmo. Twitter lo <a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm\" target=\"_blank\">había eliminado</a> en mayo y lo había sustituido por una opción manual: ahora cada usuario puede recortar la parte que quiere que se vea de la imagen que cuelga. “Es una buena opción”, cree Kulynych. La supresión del algoritmo solo elimina un pequeño problema. En el fondo, este algoritmo no era crucial: solo decidía qué partes de una foto grande mostrar. En investigaciones anteriores, algunas hechas con su tutora de tesis, la ingeniera española<a href=\"https://elpais.com/tecnologia/2020-04-15/la-ingeniera-espanola-que-lidera-la-app-europea-de-rastreo-de-contagios-no-debe-ser-un-estado-de-vigilancia.html\" target=\"_blank\"> Carmela Troncoso,</a> Kulynych<a href=\"https://arxiv.org/abs/1811.11293\" target=\"_blank\"> ha analizado el impacto</a> de otros algoritmos más importantes para las grandes tecnológicas: aquellos algoritmos esenciales que deciden qué vemos en Twitter, YouTube, Amazon o Airbnb. ¿Qué comportamientos pueden estar promoviendo en favor de los beneficios de estas empresas?</p>","<p>Ese tipo de algoritmos no se ponen de momento a disposición de investigadores externos para ver si hay sesgos o errores, dice Kulynych. Son una parte central de las tecnológicas: “Aparte de los errores, están los problemas en los algoritmos que emergen debido a la estructura de incentivos y optimización de beneficios dentro de las compañías”, dice Kulynych. “Con estos no organizan competiciones porque no son errores como tales. Solo pueden resolverse desde fuera y para ello sería necesaria la regulación para retos como la mitigación de la desinformación en redes sociales, o aumento de la gentrificación en plataformas como Airbnb. La capacidad de autorregulación de estas empresas es limitada”, añade.</p>","<p>La competición de Twitter para analizar su algoritmo caído en desgracia es loable, admite Kulynych, pero está por ver si es un primer paso o simplemente un caso aislado. Rumman Chowdhury, nueva directora (se incorporó en febrero) de Ética de Machine Learning de Twitter, dijo que no es sencillo abrir el algoritmo de recomendación de Twitter para que sea analizado desde fuera, pero “sería fascinante hacer una competición sobre sesgos de sistemas”.</p>","<p>En su discurso sobre esta competición, Chowdhury admitió la obviedad de que los sesgos de los algoritmos se basan en automatizar lo que los humanos hacemos de forma natural: “Hemos creado estos filtros porque creemos que eso es lo que es ‘bonito’, y eso termina entrenando nuestros modelos y llevándonos a estas nociones irreales de lo que significa ser atractivo”.</p>","<p>En una conversación previa en Twitter, empleados de la compañía ofrecieron una analogía para este concurso: se parece a las primeras recompensas que se dieron a quienes encontraban errores de seguridad en los programas informáticos hace años. Ahora un agujero de seguridad puede costar cientos de miles de euros o incluso millones si se vende a según quién: es un modo de acceder a sistemas sin ser detectado. Kulynych se ha llevado solo 3.500 dólares por su trabajo, que es una cantidad irrisoria para los niveles de Silicon Valley.</p>","<p>Pero quizá no quede ahí. “Al principio, los errores de seguridad se reportaban y nadie recibía nada a cambio, quizá ni se arreglaba el problema. Así nacieron las recompensas, para crear un incentivo para comunicarlos a los creadores del <i>software </i>y que los arreglaran”, dice Kulynych. La diferencia es que los problemas de seguridad pueden descubrirse desde fuera y el análisis del algoritmo requiere de la complicidad de la compañía, que debe abrirlo a análisis externo.</p>","<p>La detección del sesgo de Kulynych no fue la única. El segundo premio fue para un trabajo que también comprobaba que el algoritmo prestaba menos atención a rostros ancianos y el tercero se lo llevó otro investigador que descubrió, al comparar memes con texto, que el algoritmo prefería el lenguaje en grafías latinas respecto al árabe. Twitter dio también un premio a un investigador italiano que encontró que los emojis de piel clara también reciben mejor puntuación del algoritmo.</p>","<p><i>Puedes seguir a EL PAÍS TECNOLOGÍA en</i><a href=\"https://www.facebook.com/elpaistecnologia\"><i> Facebook</i></a><i> y </i><a href=\"https://twitter.com/elpais_tec\"><i>Twitter</i></a><i> o apuntarte aquí para recibir nuestra </i><a href=\"https://plus.elpais.com/newsletters/lnp/1/356\"><i>newsletter semanal</i></a><i>.</i></p>"],"textContent":"En septiembre de 2020, un estudiante de la Universidad de Victoria (Canadá) descubrió sin querer que Twitter destacaba más los rostros blancos al recortar las imágenes. Su hilo de tuits provocó una gran polémica y decenas de pruebas de otros tuiteros en el mismo sentido. Finalmente Twitter decidió ver qué pasaba. El proceso ha culminado este mes de agosto con una competición ―la primera de este tipo― entre informáticos a quienes se permitió analizar el algoritmo. Y se les ofreció una recompensa por sus hallazgos. El concurso confirmó que algún sesgo existía. El vencedor, el doctorando de la Universidad Politécnica de Lausane (Suiza) Bogdan Kulynych (Ucrania, 1993) ha descubierto que ciertamente el algoritmo prefiere rostros claros, jóvenes, delgados y con rasgos femeninos.El sesgo de los algoritmos no es nada nuevo. Un algoritmo de este tipo es un programa que ordena resultados a partir de datos que se le proporcionan. En el caso de Twitter escogía el fragmento (los píxeles) de una imagen que creía que iba a ser más interesante para destacarlo y que los usuarios de Twitter lo vieran en sus pantallas.Este algoritmo proviene de un modelo elaborado a partir de seguir la mirada humana cuando aparece una imagen en una pantalla. Y supuestamente los humanos prefieren caras de piel clara, femeninas, delgadas, jóvenes, y con un tono cálido y bien contrastado. En un estudio previo al concurso que hizo la propia red social, y en el que ya se veía cierto sesgo, también analizaron lo que llaman la “mirada masculina”: a veces el algoritmo se centraba en zonas del cuerpo femenino que no eran la cara, lo que, según el artículo científico, se originaba en “la representación constante de las mujeres como objetos sexuales para el placer desde la perspectiva de los hombres heterosexuales”.“En mi investigación generé varias caras artificiales y las modifiqué no arbitrariamente, sino de una manera muy específica para ver en cuáles el algoritmo incrementaba la prominencia”, explica Kulynych a EL PAÍS en una conversación por videoconferencia. Es decir, que cuando hacía un recorte automático, tendía a conservar o a destacar más dichos rostros. “Seleccioné solo un pequeño grupo de 16 caras por problemas de tiempo y porque el proceso computacional es largo. Eran caras diversas y al final vi patrones. El algoritmo daba más prominencia a caras más jóvenes, delgadas, con más calidez y rasgos femeninos”, continúa.Aunque la muestra de Kulynych es pequeña porque la competición dejaba solo una semana para participar, cree que es probable que el problema fuera “fundamental” y ocurriera igual si se repitiera con una muestra de caras mayor. “Aunque sospecho que con ese análisis más extenso la diferencia sería menos pronunciada o que los patrones serían menos claros”, aclara.Detalle del proyecto de Kulynych: aquí se ve cómo el algoritmo puntúa progresivamente mejor las imágenes de la derecha por la feminidad y la calidez en el tono de la piel.El concurso fue una especie de análisis post mortem del algoritmo. Twitter lo había eliminado en mayo y lo había sustituido por una opción manual: ahora cada usuario puede recortar la parte que quiere que se vea de la imagen que cuelga. “Es una buena opción”, cree Kulynych. La supresión del algoritmo solo elimina un pequeño problema. En el fondo, este algoritmo no era crucial: solo decidía qué partes de una foto grande mostrar. En investigaciones anteriores, algunas hechas con su tutora de tesis, la ingeniera española Carmela Troncoso, Kulynych ha analizado el impacto de otros algoritmos más importantes para las grandes tecnológicas: aquellos algoritmos esenciales que deciden qué vemos en Twitter, YouTube, Amazon o Airbnb. ¿Qué comportamientos pueden estar promoviendo en favor de los beneficios de estas empresas?Ese tipo de algoritmos no se ponen de momento a disposición de investigadores externos para ver si hay sesgos o errores, dice Kulynych. Son una parte central de las tecnológicas: “Aparte de los errores, están los problemas en los algoritmos que emergen debido a la estructura de incentivos y optimización de beneficios dentro de las compañías”, dice Kulynych. “Con estos no organizan competiciones porque no son errores como tales. Solo pueden resolverse desde fuera y para ello sería necesaria la regulación para retos como la mitigación de la desinformación en redes sociales, o aumento de la gentrificación en plataformas como Airbnb. La capacidad de autorregulación de estas empresas es limitada”, añade.La competición de Twitter para analizar su algoritmo caído en desgracia es loable, admite Kulynych, pero está por ver si es un primer paso o simplemente un caso aislado. Rumman Chowdhury, nueva directora (se incorporó en febrero) de Ética de Machine Learning de Twitter, dijo que no es sencillo abrir el algoritmo de recomendación de Twitter para que sea analizado desde fuera, pero “sería fascinante hacer una competición sobre sesgos de sistemas”.En su discurso sobre esta competición, Chowdhury admitió la obviedad de que los sesgos de los algoritmos se basan en automatizar lo que los humanos hacemos de forma natural: “Hemos creado estos filtros porque creemos que eso es lo que es ‘bonito’, y eso termina entrenando nuestros modelos y llevándonos a estas nociones irreales de lo que significa ser atractivo”.En una conversación previa en Twitter, empleados de la compañía ofrecieron una analogía para este concurso: se parece a las primeras recompensas que se dieron a quienes encontraban errores de seguridad en los programas informáticos hace años. Ahora un agujero de seguridad puede costar cientos de miles de euros o incluso millones si se vende a según quién: es un modo de acceder a sistemas sin ser detectado. Kulynych se ha llevado solo 3.500 dólares por su trabajo, que es una cantidad irrisoria para los niveles de Silicon Valley.Pero quizá no quede ahí. “Al principio, los errores de seguridad se reportaban y nadie recibía nada a cambio, quizá ni se arreglaba el problema. Así nacieron las recompensas, para crear un incentivo para comunicarlos a los creadores del software y que los arreglaran”, dice Kulynych. La diferencia es que los problemas de seguridad pueden descubrirse desde fuera y el análisis del algoritmo requiere de la complicidad de la compañía, que debe abrirlo a análisis externo.La detección del sesgo de Kulynych no fue la única. El segundo premio fue para un trabajo que también comprobaba que el algoritmo prestaba menos atención a rostros ancianos y el tercero se lo llevó otro investigador que descubrió, al comparar memes con texto, que el algoritmo prefería el lenguaje en grafías latinas respecto al árabe. Twitter dio también un premio a un investigador italiano que encontró que los emojis de piel clara también reciben mejor puntuación del algoritmo.Puedes seguir a EL PAÍS TECNOLOGÍA en Facebook y Twitter o apuntarte aquí para recibir nuestra newsletter semanal.","length":6904,"excerpt":"La red social vivió una polémica hace unos meses por cómo recortaba las imágenes. Ahora una competición pionera ganada por el doctorando ucranio Bogdan Kulynych confirma las sospechas","siteName":"EL PAÍS","image":"https://imagenes.elpais.com/resizer/OBF3f4JTynO9QR9yVeBexLXNwHc=/1200x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/FELLXOTD4VFPLCPI5GUDLNOGWA.jpg","url":"https://elpais.com/tecnologia/2021-08-19/el-algoritmo-de-twitter-preferia-caras-femeninas-y-blancas-un-concurso-de-programadores-lo-demostro.html"}}},"__N_SSG":true}